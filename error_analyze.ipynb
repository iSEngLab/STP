{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import calc_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = calc_error.calc_error_method_1(dataset_name=\"Tech\", file_path=\"results_romanian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.bar(\n",
    "    res_df,\n",
    "    x=\"model\",\n",
    "    y=\"correct\",\n",
    "    title=\"Error of the methods for the Opinion dataset\",\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_romanian/res_method_1_Tech.txt\", \"w\") as f:\n",
    "    f.write(str(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, no_correct = calc_error.calc_error_method_2(\n",
    "    dataset_name=\"Tech\", file_path=\"results_romanian\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of correct sentences:\n",
    "\n",
    "Opinion:\n",
    "\n",
    "- 3 models: 553\n",
    "- 8 models: 223\n",
    "\n",
    "Tech:\n",
    "\n",
    "- 3 models: 382\n",
    "- 8 models: 59\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_romanian/res_method_2_3_models_Tech.txt\", \"w\") as f:\n",
    "    f.write(str(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, no_correct = calc_error.calc_error_method_2(\n",
    "    dataset_name=\"Tech\",\n",
    "    file_path=\"results_romanian\",\n",
    "    threshold=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, no_correct = calc_error.calc_error_method_2(\n",
    "    dataset_name=\"Opinion\",\n",
    "    file_path=\"results_romanian\",\n",
    "    threshold=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from gensim import corpora\n",
    "\n",
    "word_token_en = {}\n",
    "word_token_cn = {}\n",
    "\n",
    "nlpEN = StanfordCoreNLP(r\"./stanford-corenlp-4.5.5\")\n",
    "\n",
    "\n",
    "def bow(l1, l2):\n",
    "    s1 = []\n",
    "    if l1 not in word_token_en.keys():\n",
    "        s1 = nlpEN.word_tokenize(l1)\n",
    "        word_token_en[l1] = s1\n",
    "    else:\n",
    "        s1 = word_token_en[l1]\n",
    "    s2 = []\n",
    "    if l2 not in word_token_en.keys():\n",
    "        s2 = nlpEN.word_tokenize(l2)\n",
    "        word_token_en[l2] = s2\n",
    "    else:\n",
    "        s2 = word_token_en[l2]\n",
    "    punc = string.punctuation\n",
    "    text1 = []\n",
    "    for i in s1:\n",
    "        if i in punc:  # type: ignore\n",
    "            continue\n",
    "        text1.append(i)\n",
    "    text2 = []\n",
    "    for i in s2:\n",
    "        if i in punc:  # type: ignore\n",
    "            continue\n",
    "        text2.append(i)\n",
    "    texts = [text1, text2]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    # 利用doc2bow作为词袋模型\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    dict1 = {}\n",
    "    dict2 = {}\n",
    "    for i, j in corpus[0]:\n",
    "        dict1[i] = j\n",
    "    for i, j in corpus[1]:\n",
    "        dict2[i] = j\n",
    "    dis = 0\n",
    "    for i in range(len(dictionary.cfs.items())):\n",
    "        if i not in dict1.keys():\n",
    "            continue\n",
    "        l1 = dict1.get(i, -1)\n",
    "        l2 = dict2.get(i, -1)\n",
    "        if l2 != l1:\n",
    "            if l2 > l1:\n",
    "                continue\n",
    "            dis = dis + abs(l1 - l2)\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of correct sentences:\n",
    "\n",
    "Opinion:\n",
    "\n",
    "- 3 models: 553\n",
    "- 8 models: 223\n",
    "\n",
    "Tech:\n",
    "\n",
    "- 3 models: 382\n",
    "- 8 models: 59\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[\n",
    "        0\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )\n",
    "\n",
    "\n",
    "def calc_similarity(\n",
    "    sentences: list[str],\n",
    "    tokenizer: AutoTokenizer,\n",
    "    model: AutoModel,\n",
    ") -> float:\n",
    "    encoded_input = tokenizer(\n",
    "        sentences,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input[\"attention_mask\"])\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    cosine_scores = F.cosine_similarity(\n",
    "        sentence_embeddings[0].unsqueeze(0),\n",
    "        sentence_embeddings[1].unsqueeze(0),\n",
    "    ).item()\n",
    "\n",
    "    return cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import dataclasses\n",
    "\n",
    "import pandas as pd\n",
    "from calc_error import calc_correct\n",
    "\n",
    "file_path = \"./results_romanian/\"\n",
    "dataset_name = \"Opinion\"\n",
    "\n",
    "df_res = {}\n",
    "\n",
    "to_analyze_res = []\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Result:\n",
    "    dataset_name: str\n",
    "    model: str\n",
    "    threshold: int\n",
    "    l1: str\n",
    "    l2: str\n",
    "    is_suspicious: bool\n",
    "    is_wrong: bool\n",
    "\n",
    "\n",
    "for dataset_name in [\"Opinion\", \"Tech\"]:\n",
    "    results = []\n",
    "    sentence_map = calc_correct(dataset_name, file_path)\n",
    "\n",
    "    for threshold in [0, 2, 4, 6, 8, 10, 12]:\n",
    "        for model_ in [\"deepl\", \"google\", \"bing\"]:\n",
    "            checkpoint_name = model_.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "            file_name = (\n",
    "                f\"./{file_path}/target_sentences_{checkpoint_name}_{dataset_name}.pkl\"\n",
    "            )\n",
    "\n",
    "            with open(f\"./{file_path}/datasetAfter_{dataset_name}.pkl\", \"rb\") as f:\n",
    "                dataset = pickle.load(f)\n",
    "\n",
    "            with open(file_name, \"rb\") as f:\n",
    "                model_sentences: dict[str, str] = pickle.load(f)\n",
    "\n",
    "            no_total = len(model_sentences)\n",
    "            no_suspicous = 0\n",
    "            no_correct = 0\n",
    "\n",
    "            for key, values in dataset.items():\n",
    "                for i in range(1, len(values)):\n",
    "                    is_suspicious = False\n",
    "                    is_wrong = False\n",
    "\n",
    "                    l1 = model_sentences.get(values[i], \"\")\n",
    "                    l2 = model_sentences.get(values[i - 1], \"\")\n",
    "                    if len(l1) > len(l2):\n",
    "                        continue\n",
    "                    res = bow(l1, l2)\n",
    "                    if res > len(l1.split(\" \")):\n",
    "                        continue\n",
    "                    if res > threshold:\n",
    "                        no_suspicous += 1\n",
    "                        is_suspicious = True\n",
    "                        if sentence_map[values[i]] is False:\n",
    "                            no_correct += 1\n",
    "                            is_wrong = True\n",
    "\n",
    "                    to_analyze_res.append(\n",
    "                        Result(\n",
    "                            dataset_name=dataset_name,\n",
    "                            model=model_,\n",
    "                            threshold=threshold,\n",
    "                            l1=l1,\n",
    "                            l2=l2,\n",
    "                            is_suspicious=is_suspicious,\n",
    "                            is_wrong=is_wrong,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            no_wrong = 0\n",
    "            if dataset_name == \"Opinion\":\n",
    "                no_wrong = no_total - 553\n",
    "            else:\n",
    "                no_wrong = no_total - 382\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"threshold\": threshold,\n",
    "                    \"model\": model_,\n",
    "                    \"correct\": no_total - no_suspicous,\n",
    "                    \"total\": no_total,\n",
    "                    \"suspicous\": no_suspicous,\n",
    "                    \"precision\": no_correct / no_suspicous * 100,\n",
    "                    \"percentage\": no_suspicous / no_total * 100,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df_res[dataset_name] = pd.DataFrame(results)\n",
    "\n",
    "    df_res[dataset_name].to_csv(\n",
    "        f\"./results_romanian/res_method_3_{dataset_name}.csv\", index=False\n",
    "    )\n",
    "\n",
    "pd.DataFrame(to_analyze_res).to_csv(\n",
    "    \"./results_romanian/res_method_3_to_analyze.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# display bar chart and line chart on the same figure\n",
    "# there are three models: deepl, google, bing and three lines\n",
    "\n",
    "for dataset_name in [\"Opinion\", \"Tech\"]:\n",
    "    df = df_res[dataset_name]\n",
    "    fig = make_subplots(\n",
    "        specs=[[{\"secondary_y\": True}]],\n",
    "        rows=1,\n",
    "        cols=1,\n",
    "    )\n",
    "    for i in [\"deepl\", \"google\", \"bing\"]:\n",
    "        fig.add_trace(\n",
    "            px.bar(\n",
    "                df.query(f\"model == '{i}'\"),\n",
    "                x=\"threshold\",\n",
    "                y=\"suspicous\",\n",
    "                color=\"model\",\n",
    "                color_discrete_map={\"deepl\": \"blue\", \"google\": \"green\", \"bing\": \"red\"},\n",
    "            ).data[0],\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "    for i in [\"deepl\", \"google\", \"bing\"]:\n",
    "        fig.add_trace(\n",
    "            px.line(\n",
    "                df.query(f\"model == '{i}'\"),\n",
    "                x=\"threshold\",\n",
    "                y=\"precision\",\n",
    "                color=\"model\",\n",
    "                color_discrete_map={\n",
    "                    \"deepl\": \"darkblue\",\n",
    "                    \"google\": \"darkgreen\",\n",
    "                    \"bing\": \"darkred\",\n",
    "                },\n",
    "            ).data[0],\n",
    "            secondary_y=True,\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Error of the methods for the {dataset_name} dataset\",\n",
    "        xaxis_title=\"Threshold\",\n",
    "        yaxis_title=\"Number of suspicious sentences\",\n",
    "        yaxis2_title=\"Precision\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "file_path = \"./results_romanian/\"\n",
    "dataset_name = \"Opinion\"\n",
    "\n",
    "\n",
    "for dataset_name in [\"Opinion\", \"Tech\"]:\n",
    "    results = []\n",
    "    for threshold in [0, 2, 4, 6, 8, 10, 12]:\n",
    "        for model_ in [\n",
    "            \"deepl\",\n",
    "            \"google\",\n",
    "            \"bing\",\n",
    "            \"Helsinki-NLP/opus-mt-en-ro\",\n",
    "            \"Helsinki-NLP/opus-tatoeba-en-ro\",\n",
    "            \"Helsinki-NLP/opus-mt-tc-big-en-ro\",\n",
    "            \"facebook/mbart-large-en-ro\",\n",
    "            \"BlackKakapo/opus-mt-en-ro\",\n",
    "        ]:\n",
    "            checkpoint_name = model_.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "            file_name = (\n",
    "                f\"./{file_path}/target_sentences_{checkpoint_name}_{dataset_name}.pkl\"\n",
    "            )\n",
    "\n",
    "            with open(f\"./{file_path}/datasetAfter_{dataset_name}.pkl\", \"rb\") as f:\n",
    "                dataset = pickle.load(f)\n",
    "\n",
    "            with open(file_name, \"rb\") as f:\n",
    "                model_sentences: dict[str, str] = pickle.load(f)\n",
    "\n",
    "            no_total = len(model_sentences)\n",
    "            no_suspicous = 0\n",
    "\n",
    "            for key, values in dataset.items():\n",
    "                if len(values) == 0:\n",
    "                    continue\n",
    "                res = bow(values[0], key)\n",
    "                if res > threshold:\n",
    "                    no_suspicous += 1\n",
    "\n",
    "                for i in range(1, len(values)):\n",
    "                    l1 = model_sentences.get(values[i], \"\")\n",
    "                    l2 = model_sentences.get(values[i - 1], \"\")\n",
    "                    if len(l1) > len(l2):\n",
    "                        continue\n",
    "                    res = bow(l1, l2)\n",
    "                    if res > len(l1.split(\" \")):\n",
    "                        continue\n",
    "                    if res > threshold:\n",
    "                        no_suspicous += 1\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"threshold\": threshold,\n",
    "                    \"model\": model_,\n",
    "                    \"correct\": no_total - no_suspicous,\n",
    "                    \"total\": no_total,\n",
    "                    \"suspicous\": no_suspicous,\n",
    "                    \"percentage\": no_suspicous / no_total * 100,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    px.bar(\n",
    "        pd.DataFrame(results),\n",
    "        x=\"threshold\",\n",
    "        y=\"suspicous\",\n",
    "        color=\"model\",\n",
    "        barmode=\"group\",\n",
    "        title=f\"Error of the methods for the {dataset_name} dataset\",\n",
    "    ).show()\n",
    "\n",
    "    px.bar(\n",
    "        pd.DataFrame(results),\n",
    "        x=\"threshold\",\n",
    "        y=\"suspicous\",\n",
    "        color=\"model\",\n",
    "        barmode=\"group\",\n",
    "        title=f\"Error of the methods for the {dataset_name} dataset (percentage)\",\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import dataclasses\n",
    "\n",
    "import pandas as pd\n",
    "from calc_error import calc_correct\n",
    "\n",
    "file_path = \"./results_romanian/\"\n",
    "\n",
    "df_res = {}\n",
    "\n",
    "to_analyze_res = []\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Result:\n",
    "    dataset_name: str\n",
    "    model: str\n",
    "    threshold: int\n",
    "    l1: str\n",
    "    l2: str\n",
    "    is_suspicious: bool\n",
    "    is_wrong: bool\n",
    "\n",
    "\n",
    "for dataset_name in [\"Opinion\", \"Tech\"]:\n",
    "    results = []\n",
    "    sentence_map = calc_correct(dataset_name, file_path)\n",
    "\n",
    "    for threshold in [0, 2, 4, 6, 8, 10, 12]:\n",
    "        for model_ in [\n",
    "            \"deepl\",\n",
    "            \"google\",\n",
    "            \"bing\",\n",
    "            \"Helsinki-NLP/opus-mt-en-ro\",\n",
    "            \"Helsinki-NLP/opus-tatoeba-en-ro\",\n",
    "            \"Helsinki-NLP/opus-mt-tc-big-en-ro\",\n",
    "            \"facebook/mbart-large-en-ro\",\n",
    "            \"BlackKakapo/opus-mt-en-ro\",\n",
    "        ]:\n",
    "            checkpoint_name = model_.replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "            file_name = (\n",
    "                f\"./{file_path}/target_sentences_{checkpoint_name}_{dataset_name}.pkl\"\n",
    "            )\n",
    "\n",
    "            with open(f\"./{file_path}/datasetAfter_{dataset_name}.pkl\", \"rb\") as f:\n",
    "                dataset = pickle.load(f)\n",
    "\n",
    "            with open(file_name, \"rb\") as f:\n",
    "                model_sentences: dict[str, str] = pickle.load(f)\n",
    "\n",
    "            no_total = len(model_sentences)\n",
    "            no_suspicous = 0\n",
    "            no_correct = 0\n",
    "\n",
    "            for key, values in dataset.items():\n",
    "                for i in range(1, len(values)):\n",
    "                    is_suspicious = False\n",
    "                    is_wrong = False\n",
    "\n",
    "                    l1 = model_sentences.get(values[i], \"\")\n",
    "                    l2 = model_sentences.get(values[i - 1], \"\")\n",
    "                    if len(l1) > len(l2):\n",
    "                        continue\n",
    "                    res = bow(l1, l2)\n",
    "                    if res > len(l1.split(\" \")):\n",
    "                        continue\n",
    "                    if res > threshold:\n",
    "                        no_suspicous += 1\n",
    "                        is_suspicious = True\n",
    "                        if sentence_map[values[i]] is False:\n",
    "                            no_correct += 1\n",
    "                            is_wrong = True\n",
    "\n",
    "                    to_analyze_res.append(\n",
    "                        Result(\n",
    "                            dataset_name=dataset_name,\n",
    "                            model=model_,\n",
    "                            threshold=threshold,\n",
    "                            l1=l1,\n",
    "                            l2=l2,\n",
    "                            is_suspicious=is_suspicious,\n",
    "                            is_wrong=is_wrong,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            no_wrong = 0\n",
    "            if dataset_name == \"Opinion\":\n",
    "                no_wrong = no_total - 553\n",
    "            else:\n",
    "                no_wrong = no_total - 382\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"threshold\": threshold,\n",
    "                    \"model\": model_,\n",
    "                    \"correct\": no_total - no_suspicous,\n",
    "                    \"total\": no_total,\n",
    "                    \"suspicous\": no_suspicous,\n",
    "                    \"precision\": no_correct / no_suspicous * 100,\n",
    "                    \"percentage\": no_suspicous / no_total * 100,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df_res[dataset_name] = pd.DataFrame(results)\n",
    "\n",
    "    df_res[dataset_name].to_csv(\n",
    "        f\"./results_romanian/res_method_8_{dataset_name}.csv\", index=False\n",
    "    )\n",
    "\n",
    "pd.DataFrame(to_analyze_res).to_csv(\n",
    "    \"./results_romanian/res_method_8_to_analyze.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# display bar chart and line chart on the same figure\n",
    "# there are three models: deepl, google, bing and three lines\n",
    "\n",
    "models = [\n",
    "    \"deepl\",\n",
    "    \"google\",\n",
    "    \"bing\",\n",
    "    \"Helsinki-NLP/opus-mt-en-ro\",\n",
    "    \"Helsinki-NLP/opus-tatoeba-en-ro\",\n",
    "    \"Helsinki-NLP/opus-mt-tc-big-en-ro\",\n",
    "    \"facebook/mbart-large-en-ro\",\n",
    "    \"BlackKakapo/opus-mt-en-ro\",\n",
    "]\n",
    "\n",
    "color_discrete_map = {\n",
    "    \"deepl\": \"blue\",\n",
    "    \"google\": \"green\",\n",
    "    \"bing\": \"red\",\n",
    "    \"Helsinki-NLP/opus-mt-en-ro\": \"cyan\",\n",
    "    \"Helsinki-NLP/opus-tatoeba-en-ro\": \"goldenrod\",\n",
    "    \"Helsinki-NLP/opus-mt-tc-big-en-ro\": \"khaki\",\n",
    "    \"facebook/mbart-large-en-ro\": \"magenta\",\n",
    "    \"BlackKakapo/opus-mt-en-ro\": \"salmon\",\n",
    "}\n",
    "\n",
    "for dataset_name in [\"Opinion\", \"Tech\"]:\n",
    "    df = df_res[dataset_name]\n",
    "    fig = make_subplots(\n",
    "        specs=[[{\"secondary_y\": True}]],\n",
    "        rows=1,\n",
    "        cols=1,\n",
    "    )\n",
    "    for i in models:\n",
    "        fig.add_trace(\n",
    "            px.bar(\n",
    "                df.query(f\"model == '{i}'\"),\n",
    "                x=\"threshold\",\n",
    "                y=\"suspicous\",\n",
    "                color=\"model\",\n",
    "                color_discrete_map=color_discrete_map,\n",
    "            ).data[0],\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "    for i in models:\n",
    "        fig.add_trace(\n",
    "            px.line(\n",
    "                df.query(f\"model == '{i}'\"),\n",
    "                x=\"threshold\",\n",
    "                y=\"precision\",\n",
    "                color=\"model\",\n",
    "                color_discrete_map={\n",
    "                    key: f\"dark{value}\" for key, value in color_discrete_map.items()\n",
    "                },\n",
    "            ).data[0],\n",
    "            secondary_y=True,\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Error of the methods for the {dataset_name} dataset\",\n",
    "        xaxis_title=\"Threshold\",\n",
    "        yaxis_title=\"Number of suspicious sentences\",\n",
    "        yaxis2_title=\"Precision\",\n",
    "        height=600,\n",
    "    )\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-stp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
